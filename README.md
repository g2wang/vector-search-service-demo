# Rust Axum Vector Search API with Qdrant and Local Embedding Model 
(Used ChatGPT, DeepSeek and Claude for implementation ideas and code samples.)

This project implements a web server using **Rust**, **Axum**, **Qdrant**, and a local **all-MiniLM-L6-v2** text embedding model to store and search vectorized docs.

## ğŸš€ **Features**
- **Add Doc Endpoint:** Vectorizes input text and stores it in Qdrant.
- **Search Doc Endpoint:** Finds the most relevant stored doc using vector search.
- **Local Embedding Model:** Uses a local ONNX model for embeddings.
- **Thread-Safe State:** Efficiently shares model and clients across routes.
- **Long Text Handling:** split into chunks and use weighted mean.

---
## ğŸ› ï¸ **Setup Instructions**
### 1. **Clone the Repository:**
```bash
git clone https://github.com/g2wang/vector-search-service-demo.git
cd vector-search-service-demo
```

### 2. **Install Dependencies:**
```bash
cargo build
# or cargo build --release
```

### 3. **Set Environment Variables:** Create a `.env` file:
```env
QDRANT_URL=http://localhost:6333
SERVER_URL=127.0.0.1:3000
```

---
## ğŸš€ **Run the Server:**
```bash
# first start the Qdrant vector database server
./start_qdrant.sh

# then start the service
cargo run
# alternatively, run the executable generated by cargo build
```
The server will start at: **http://127.0.0.1:3000**

---
## ğŸš€ **Test the API Endpoints:**
```bash
./add_doc.sh
./query_doc.sh
```

---
## ğŸ“¡ **API Endpoints:**
### 1. Add Doc (`POST /doc`)
- **Request:**
```json
{
  "text": "This is a helpful doc!"
}
```
- **Response:**
```json
{
  "status": "success"
}
```

### 2. Search Doc (`POST /search`)
- **Request:**
```json
{
  "text": "Find a doc about..."
}
```
- **Response:**
```json
[
  {
    "text": "This is a helpful doc!",
    "score": 0.98
  }
]
```
---
## ğŸ“‚ **Project Structure:**
```
src
â”œâ”€â”€ all_minilm_l6_v2
â”‚Â Â  â”œâ”€â”€ mod.rs
â”‚Â Â  â””â”€â”€ models
â”‚Â Â      â”œâ”€â”€ README.txt
â”‚Â Â      â”œâ”€â”€ config.json
â”‚Â Â      â”œâ”€â”€ onnx
â”‚Â Â      â”‚Â Â  â””â”€â”€ model.onnx
â”‚Â Â      â”œâ”€â”€ special_tokens_map.json
â”‚Â Â      â”œâ”€â”€ tokenizer.json
â”‚Â Â      â””â”€â”€ tokenizer_config.json
â”œâ”€â”€ embedding.rs
â”œâ”€â”€ main.rs
â”œâ”€â”€ qdrant_util.rs
â”œâ”€â”€ splitter.rs
â”œâ”€â”€ thread_safty.rs
â””â”€â”€ vector_mean.rs
```
---
## ğŸ’¡ **Contributing:**
Feel free to open issues or pull requests to improve this project.

## ğŸ“ **License:** MIT License
